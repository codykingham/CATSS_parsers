{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Parallel Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clean dataset is a modernization of the CATSS Database, presented with minimal changes, in UTF8, exported as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex \n",
    "import collections\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from greekutils import beta2unicode # do: pip install greek-utils==0.2\n",
    "from pprint import pprint\n",
    "\n",
    "data = Path('../source/patched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCAT transcription to UTF8\n",
    "# Greek to be handled by greekutils\n",
    "\n",
    "# Hebrew\n",
    "trans2utf8 = {\n",
    "    ')': 'א',\n",
    "    'B': 'ב',\n",
    "    'G': 'ג',\n",
    "    'D': 'ד',\n",
    "    'H': 'ה',\n",
    "    'W': 'ו',\n",
    "    'Z': 'ז',\n",
    "    'X': 'ח',\n",
    "    '+': 'ט',\n",
    "    'Y': 'י',\n",
    "    'K': 'כ',\n",
    "    'L': 'ל',\n",
    "    'M': 'מ',\n",
    "    'N': 'נ',\n",
    "    'S': 'ס',\n",
    "    '(': 'ע',\n",
    "    'P': 'פ',\n",
    "    'C': 'צ',\n",
    "    'Q': 'ק',\n",
    "    'R': 'ר',\n",
    "    '&': 'שׂ',\n",
    "    '$': 'שׁ',\n",
    "    'T': 'ת',\n",
    "    '-': '־',\n",
    "    '\\\\': '',\n",
    "    ' ': ' ',\n",
    "}\n",
    "\n",
    "def utf8_hebrew(string):\n",
    "    \"\"\"Convert transcribed Hebrew to UTF8\n",
    "    \n",
    "    NB: does not provide final letters (e.g. ם).\n",
    "    \"\"\"\n",
    "    utf8_string = ''\n",
    "    for c in string:\n",
    "        utf8_string += trans2utf8.get(c, '')\n",
    "    return utf8_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'συναγωγὴν'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta2unicode.convert('SUNAGWGH\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'היתה שׁמ בבית־לחממ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utf8_hebrew('HYTH $M B\\BYT-LXMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the files\n",
    "\n",
    "We process the CATSS database files into JSONs. \n",
    "\n",
    "The datastructure is illustrated below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[ # list of verses\n",
    "    \n",
    "    [ # list data for a verse\n",
    "    \n",
    "        'Gen 1:9',     # verse reference\n",
    "        \n",
    "        [ # three-list of text columns\n",
    "            \n",
    "            [ # Hebrew column A\n",
    "                ('מקום', ''), # text entry + text critical notes\n",
    "            ],\n",
    "            \n",
    "            [ # Hebrew column B\n",
    "                ('מקוה', '?'), # text entry + text critical notes\n",
    "            ], \n",
    "            \n",
    "            [ # Greek column\n",
    "                ('συναγωγὴν', ''), # text entry + text critical notes\n",
    "            ],   \n",
    "        ],\n",
    "    ],\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each list consists of a single verse, headed by a reference string. The \n",
    "second element in the list is a three-list of two-tuples.\n",
    "\n",
    "Each two-tuple represents a column in the database, and they consist \n",
    "of `(text, text-critical notes)`. Hebrew column B contains retroverted\n",
    "readings and it is frequently empty.\n",
    "\n",
    "Each column can contain multiple text entries, for cases where there are \n",
    "separate notes per column. For instance, the database might contain \n",
    "words wrapped in curly brackets `{}` with notations that are separate\n",
    "from another word that is not contained in them. Thus, each column\n",
    "can contain more than 1 entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 1), match='['>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.match('\\[' , '[')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W/YR (+L']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `+` can either serve as the Hebrew ט or as part of a text critical sigla\n",
    "# for this reason, we require more powerful regex patterns, particularly\n",
    "# nested sets; the patterns are composed in such a way as to distinguish\n",
    "# between the two different uses of `+`\n",
    "hchars = r')BGDHWZXYKLMNS(PCQR&$T/'\n",
    "hebrew_re = regex.compile(fr'\\+*[{hchars}]+[{hchars}+ ]*')\n",
    "\n",
    "# NB, with regard to '+' below, \n",
    "# see 01.Genesis.100; + is ambiguous there immediately\n",
    "# following `=;`. We should instead recognize `+` in the \n",
    "# future in only its limiting contexts, i.e., following `-`\n",
    "# when found in TC column; if found elsewhere this should be noted\n",
    "hebrew_tc = regex.compile(fr'\\[[^{hchars}]+\\]|<[^{hchars}]+>|\\+*[^{hchars} +]+[[^{hchars} ]+]*', flags=regex.V1) # flag for nested set\n",
    "\n",
    "gchars = r'ABGDEVZHQIKLMNCOPRSJTUFXYW)(|/\\\\=+'\n",
    "greek_re = regex.compile(fr'[{gchars}]+[{gchars} ]*')\n",
    "greek_tc = regex.compile(fr'\\[[^{gchars}]+\\]|<[^{gchars}]+>|[^{gchars} ]+')\n",
    "\n",
    "hb_string = \"<1.34 this note> +-  [12c.3a] '' =;W/YR (+L\"\n",
    "hebrew_re.findall(hb_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<1.34 this note>', '+-', '[12c.3a]', \"''\", '=;']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hebrew_tc.findall(hb_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['METE/XEIN ', 'AU)TOU/S\\\\']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gk_string = 'METE/XEIN {...AU)TOU/S\\} [e2.2 3.63]'\n",
    "\n",
    "greek_re.findall(gk_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{...', '}', '[e2.2 3.63]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greek_tc.findall(gk_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_data = []\n",
    "\n",
    "# -- regex patterns --\n",
    "ref_string = regex.compile(r'^[A-Za-z1-9/]+ \\d+:?\\d*$') # e.g. 'Gen 1:3'\n",
    "continued_column = regex.compile(r'[^\\s]+.*#\\s*$') # '#' at end of col preceded by some non-space char\n",
    "content = regex.compile(r'.*[^\\s].*') # string has some non-space char (content)\n",
    "\n",
    "def line_is_continued(col1, col2):\n",
    "    \"\"\"Return boolean whether any column in a line is continued in next line\"\"\"\n",
    "    if continued_column.match(col1) or continued_column.match(col2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_dataline(line):\n",
    "    \"\"\"Return boolean on whether a line contains data content\"\"\"\n",
    "    return all([\n",
    "        content.match(line), \n",
    "        not ref_string.match(line)\n",
    "    ])\n",
    "\n",
    "def get_continued_columns(lines, counter):\n",
    "    \"\"\"Recursively retrieve data-lines continued on next line (marked with #).\n",
    "    \n",
    "    The function recursively retrieves subsequent lines if a starting line\n",
    "    is marked with a continuation marker (#). Each line that is retrieved\n",
    "    must be split into its columns, and those columns in turn must be \n",
    "    checked for continuation markers. This is done recursively until there\n",
    "    is no continuation marker found. The function retrieves the lines using \n",
    "    the current index position; it advances the index by adding 1 each time. \n",
    "    It yields all additional columns it finds as 2-tuples.\n",
    "    \"\"\"\n",
    "    line = lines[counter]\n",
    "    if is_dataline(line):\n",
    "        heb_col, grk_col = line.split('\\t')\n",
    "        if line_is_continued(heb_col, grk_col):\n",
    "            counter += 1\n",
    "            next_cols = lines[counter].split('\\t')\n",
    "            yield next_cols\n",
    "            yield from get_continued_columns(lines, counter) # recursive call here\n",
    "\n",
    "def transcribe_hebrew(string):\n",
    "    \"\"\"Transcribe a string of Hebrew column text from the parallel database.\"\"\"\n",
    "    pass\n",
    "\n",
    "def transcribe_greek(string):\n",
    "    \"\"\"Transcribe a string of Greek column text from the parallel database.\"\"\"\n",
    "    pass\n",
    "\n",
    "def clean_text(string, lang='hebrew'):\n",
    "    \"\"\"Clean string of text from the parallel database.\"\"\"\n",
    "    pass\n",
    "\n",
    "# analysis data\n",
    "test = []\n",
    "errors = []\n",
    "\n",
    "tc_inventory = collections.defaultdict(lambda: collections.Counter())\n",
    "tc_refs = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "\n",
    "cross_refs = regex.compile(r'\\<.*\\d+.*?\\>|\\[.*\\d+.*?\\]')\n",
    "num_repl = regex.compile(r'\\d+')\n",
    "\n",
    "# process files\n",
    "for file in sorted(data.glob('*.par')):\n",
    "    \n",
    "    # read the file\n",
    "    lines = file.read_text().split('\\n')\n",
    "    \n",
    "    verse_data = []\n",
    "    position = 0\n",
    "    \n",
    "    while position < len(lines):\n",
    "    \n",
    "        line = lines[position]\n",
    "    \n",
    "        # detect a new verse at verse reference string\n",
    "        if ref_string.match(line):\n",
    "            \n",
    "            # store last verse, make space for new one, store new one\n",
    "            if verse_data:\n",
    "                para_data.append(verse_data)\n",
    "                verse_data = []\n",
    "            verse_data.append(line)\n",
    "        \n",
    "        elif line:\n",
    "            \n",
    "            # for debugging\n",
    "            show_tuple = (file.name, position, verse_data[0], line)\n",
    "            \n",
    "            # extract the two columns\n",
    "            heb_col, grk_col = line.split('\\t')\n",
    "            \n",
    "            # NB: that for Sirach the Hebrew columns can sometimes\n",
    "            # be split several ways since there are numerous Hebrew \n",
    "            # sources, deriving from various manuscripts\n",
    "            # the sources are indicated by a following number;\n",
    "            # thus, it may be possible to split along stand-alone integers\n",
    "            # to divide up the text\n",
    "            \n",
    "            # seperate heb col a and b (optional)\n",
    "            if '=' in heb_col:\n",
    "                # TODO: **VERY IMPORTANT**:\n",
    "                # column B can have multiple elements with `=` prepended\n",
    "                # so instead of a split we should index and split to preserve'\n",
    "                # the first `=` sign; this should allow all discrete symbols\n",
    "                # to parsed alongside the `=` sign\n",
    "                heb_colA, heb_colB = heb_col.split('=', 1)\n",
    "            else:\n",
    "                heb_colA = heb_col\n",
    "                heb_colB = ''\n",
    "            \n",
    "            # compile inventory of TC values\n",
    "            for lang, lang_tc, col in [('hb', hebrew_tc, heb_col), ('gk', greek_tc, grk_col)]:\n",
    "                \n",
    "                for sigla in lang_tc.findall(col):\n",
    "                    \n",
    "                    no_num_sigla = num_repl.sub('\\d', sigla)\n",
    "                    \n",
    "                    # count the sigla\n",
    "                    if cross_refs.findall(sigla):\n",
    "                        tc_inventory['crossrefs'][no_num_sigla] += 1\n",
    "                        tc_refs['crossrefs'][no_num_sigla].append(show_tuple)\n",
    "                    else:\n",
    "                        tc_inventory[lang][no_num_sigla] += 1\n",
    "                        tc_refs[lang][no_num_sigla].append(show_tuple)\n",
    "            \n",
    "            # collect parts of the columns continued on next line(s) in doc\n",
    "            # this is done recursively to ensure all lines are retrieved\n",
    "            cont_cols = list(get_continued_columns(lines, position))\n",
    "\n",
    "            for hb_cc, gk_cc in cont_cols:\n",
    "                position += 1\n",
    "                heb_col += hb_cc\n",
    "                grk_col += gk_cc\n",
    "\n",
    "        # it's an empty line; move on\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        position += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gk has 114 different tc notes\n",
      "hb has 584 different tc notes\n",
      "crossrefs has 281 different tc notes\n"
     ]
    }
   ],
   "source": [
    "for lang, values in tc_inventory.items():\n",
    "    print(lang + ' has', len(values), 'different tc notes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export spreadsheets to investigate all sigla\n",
    "\n",
    "for lang in ('hb', 'gk'):\n",
    "    inv_data = []\n",
    "    for sigla, count in tc_inventory[lang].items():\n",
    "        exs = tc_refs[lang][sigla]\n",
    "        ex1 = exs[0]\n",
    "        ex_str = f'{ex1[0]}.{ex1[1]} {ex1[-1]}'\n",
    "        select_exs = '; '.join(e[2] for e in exs[1:12])\n",
    "        sigla = sigla.replace('=', \"'=\")\n",
    "        inv_data.append((sigla, count, ex_str, select_exs))\n",
    "    inv_df = pd.DataFrame(inv_data, columns=['sigla', 'freq', 'ex', 'other exs'])\n",
    "    inv_df.to_csv(f'{lang}_tc_inventory.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('05.Deut.par', 11172, 'Deut 24:20', \"--+ '' =;KI <24.22>\\tO(/TI\")\n",
      "\n",
      "('17.1Esdras.par', 6514, '1Esdr 9:32', ')L(ZR =:)LIW(NY\\tE)LIWNA=S [e10.31]')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show = tc_refs['hb']['I']\n",
    "#show = test\n",
    "\n",
    "for case in show[:100]:\n",
    "    pprint(case)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_inventory = pd.DataFrame.from_dict(tc_inventory['hb'], orient='index').sort_values(by=0, ascending=False)\n",
    "\n",
    "hb_inventory.to_csv('hb_tc_inventory.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_inventory = pd.DataFrame.from_dict(tc_inventory['gk'], orient='index').sort_values(by=0, ascending=False)\n",
    "\n",
    "gk_inventory.to_csv('gk_tc_inventory.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('--+', 20102),\n",
       " (',,a', 10635),\n",
       " ('\\\\d', 9372),\n",
       " (\"''\", 8722),\n",
       " ('=', 8675),\n",
       " ('{...}', 6263),\n",
       " ('[..]', 4531),\n",
       " ('=;', 3740),\n",
       " ('^', 3719),\n",
       " ('*', 2903),\n",
       " ('}', 2175),\n",
       " ('=:', 1825),\n",
       " ('=@', 1525),\n",
       " ('**', 1493),\n",
       " ('=v', 1298),\n",
       " ('{...', 1235),\n",
       " ('=?', 935),\n",
       " ('<sp>', 893),\n",
       " ('^^^', 868),\n",
       " ('=%p', 776),\n",
       " ('=%vap', 495),\n",
       " ('{\\\\d}', 487),\n",
       " ('=??', 485),\n",
       " ('{x}', 464),\n",
       " ('=%p+', 419),\n",
       " ('{d}', 395),\n",
       " (']', 389),\n",
       " ('=%p-', 377),\n",
       " ('{..r', 366),\n",
       " ('{!}p', 344),\n",
       " ('.m', 333),\n",
       " ('=%vpa', 328),\n",
       " ('{!}nd', 327),\n",
       " ('{**}', 290),\n",
       " ('{...?', 283),\n",
       " ('.', 280),\n",
       " ('[', 273),\n",
       " ('.dr', 270),\n",
       " ('.rd', 234),\n",
       " ('=@?', 219),\n",
       " ('=+', 211),\n",
       " ('{..^', 207),\n",
       " ('?', 195),\n",
       " ('#', 179),\n",
       " ('{*}', 174),\n",
       " (',', 172),\n",
       " ('.yw', 147),\n",
       " ('.wy', 135),\n",
       " ('=vs', 128),\n",
       " ('<<', 124),\n",
       " ('>>', 115),\n",
       " ('={d}', 113),\n",
       " ('a', 103),\n",
       " ('>\\\\d', 92),\n",
       " ('=?@', 78),\n",
       " ('.j', 78),\n",
       " ('.s', 75),\n",
       " ('*[', 75),\n",
       " ('<sp^>', 68),\n",
       " ('{!}-', 66),\n",
       " ('---', 65),\n",
       " ('.nm', 61),\n",
       " ('=r', 61),\n",
       " (\"''=\", 61),\n",
       " ('=:?', 56),\n",
       " ('.mn', 55),\n",
       " ('<', 53),\n",
       " ('-', 52),\n",
       " ('.bm', 50),\n",
       " ('*[..]', 49),\n",
       " ('>{\\\\d}', 42),\n",
       " ('{..?', 41),\n",
       " ('{!}', 40),\n",
       " ('.y-', 40),\n",
       " ('.w-', 40),\n",
       " ('.w', 38),\n",
       " ('{!}na', 34),\n",
       " ('{d?}', 33),\n",
       " ('{!}pd', 28),\n",
       " ('{!}v', 28),\n",
       " ('>[', 28),\n",
       " ('={d}@', 27),\n",
       " ('.mb', 25),\n",
       " ('={...}', 25),\n",
       " ('.h', 24),\n",
       " ('.xh', 23),\n",
       " ('{?\\\\d}', 23),\n",
       " ('>', 22),\n",
       " ('.hx', 22),\n",
       " (\"'\", 21),\n",
       " ('.nr', 20),\n",
       " ('h', 20),\n",
       " ('=;+', 19),\n",
       " ('.kb', 18),\n",
       " ('{!}ad', 16),\n",
       " ('{!}nd+', 16),\n",
       " ('{!}ndd', 16),\n",
       " ('.bp', 16),\n",
       " ('x', 15),\n",
       " ('{!}p+', 15),\n",
       " ('.z', 15),\n",
       " ('??', 15),\n",
       " ('.rn', 14),\n",
       " ('y', 14),\n",
       " (',@', 14),\n",
       " ('.y+', 14),\n",
       " ('.bk', 14),\n",
       " ('.x', 13),\n",
       " ('.r', 13),\n",
       " ('---+', 12),\n",
       " ('.h-', 12),\n",
       " ('.pb', 12),\n",
       " ('=.dt', 12),\n",
       " ('@', 11),\n",
       " ('{!}aj', 11),\n",
       " ('=@a', 11),\n",
       " ('*-', 11),\n",
       " ('.br', 10),\n",
       " ('=;{...}', 10),\n",
       " ('.d', 10),\n",
       " ('={d}?', 10),\n",
       " ('=;r', 10),\n",
       " ('w', 9),\n",
       " (':', 9),\n",
       " ('^?', 9),\n",
       " ('*z', 9),\n",
       " ('.x-', 9),\n",
       " ('.kn', 9),\n",
       " ('*>>', 9),\n",
       " ('\\\\d#', 9),\n",
       " ('q', 8),\n",
       " ('n', 8),\n",
       " ('=v?', 8),\n",
       " ('.rb', 8),\n",
       " ('{!}pc', 8),\n",
       " ('.wz', 8),\n",
       " ('^=', 8),\n",
       " ('.rk', 8),\n",
       " ('.ry', 8),\n",
       " ('r', 8),\n",
       " ('.kd', 8),\n",
       " ('c', 7),\n",
       " ('<sp', 7),\n",
       " ('.dt', 7),\n",
       " ('t', 7),\n",
       " ('k', 7),\n",
       " ('.nz', 7),\n",
       " ('<\\\\d.\\\\d', 7),\n",
       " ('=r?', 7),\n",
       " ('=?%p+', 7)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_inventory['hb'].most_common(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('---', 17561),\n",
       " (\"''\", 7784),\n",
       " ('}', 7349),\n",
       " (\"'\", 4272),\n",
       " ('^', 3717),\n",
       " ('{..^', 2809),\n",
       " ('{...', 2060),\n",
       " ('{..p', 1584),\n",
       " ('{---%}', 1346),\n",
       " ('{d}', 1028),\n",
       " ('{t}', 935),\n",
       " ('^^^', 867),\n",
       " ('{...}', 744),\n",
       " ('{..d', 588),\n",
       " ('{x}', 562),\n",
       " ('?', 477),\n",
       " ('#', 358),\n",
       " ('{p}', 289),\n",
       " ('{t?}', 288),\n",
       " ('{', 189),\n",
       " ('{d?}', 165),\n",
       " ('{...?', 137),\n",
       " (\"'}\", 71),\n",
       " ('{c', 54),\n",
       " ('{s}', 47),\n",
       " ('?}', 28),\n",
       " ('{..?', 28),\n",
       " ('[\\\\d.\\\\d', 22),\n",
       " ('--', 20),\n",
       " ('*', 19),\n",
       " ('{..d?', 15),\n",
       " ('---?', 15),\n",
       " (\"---''\", 14),\n",
       " ('{..^?', 14),\n",
       " ('-', 13),\n",
       " ('s', 13),\n",
       " ('~', 12),\n",
       " ('{..', 11),\n",
       " ('{d}{...', 9),\n",
       " ('----', 8),\n",
       " ('[e\\\\d.\\\\d', 8),\n",
       " ('{...^', 7),\n",
       " ('{?d}', 7),\n",
       " ('{c?', 5),\n",
       " ('{..r', 5),\n",
       " ('}?', 5),\n",
       " ('{d}?', 5),\n",
       " ('{z}', 5),\n",
       " ('{c}', 3),\n",
       " ('{d?}{...', 3),\n",
       " ('[cc\\\\d.\\\\d', 3),\n",
       " ('{..~', 3),\n",
       " ('{..p?', 2),\n",
       " ('{..^.', 2),\n",
       " ('{...d', 2),\n",
       " ('{...p', 2),\n",
       " ('[c', 2),\n",
       " (']', 2),\n",
       " ('{g', 2),\n",
       " ('}}', 1),\n",
       " ('{....}', 1),\n",
       " ('?^', 1),\n",
       " ('{t.}', 1),\n",
       " ('{....', 1),\n",
       " ('<t?>', 1),\n",
       " ('{pm}', 1),\n",
       " ('\\\\d}', 1),\n",
       " ('<fm', 1),\n",
       " ('---}', 1),\n",
       " ('{..p}', 1),\n",
       " ('[\\\\d.\\\\di', 1),\n",
       " ('{c}?', 1),\n",
       " ('--?', 1),\n",
       " ('{dt}', 1),\n",
       " (':', 1),\n",
       " ('-.-', 1),\n",
       " ('??', 1),\n",
       " ('\\x1b', 1),\n",
       " ('d}', 1),\n",
       " ('\\\\d\\x1b', 1),\n",
       " ('[e\\\\d', 1),\n",
       " ('\\\\d', 1),\n",
       " ('\\x7f', 1),\n",
       " ('{...d?', 1),\n",
       " ('{..p^', 1),\n",
       " ('}{...', 1),\n",
       " ('!', 1),\n",
       " ('{**}', 1),\n",
       " ('{*}', 1),\n",
       " ('ne', 1),\n",
       " ('{c?}{', 1),\n",
       " ('{...}?', 1),\n",
       " ('{.\\\\d.d', 1),\n",
       " ('{..^{p}', 1),\n",
       " ('[\\\\da', 1),\n",
       " ('?{d}', 1),\n",
       " ('{d}{..^', 1),\n",
       " ('{d}{', 1),\n",
       " ('{#}', 1),\n",
       " ('{c?}', 1),\n",
       " ('..^', 1),\n",
       " ('^^^}', 1),\n",
       " ('c', 1),\n",
       " ('no', 1),\n",
       " ('id.', 1),\n",
       " ('}{d}', 1),\n",
       " ('{g}', 1),\n",
       " ('{...r', 1),\n",
       " ('___', 1),\n",
       " ('---?,{..d', 1),\n",
       " ('?--', 1),\n",
       " ('...', 1),\n",
       " ('[t}', 1),\n",
       " ('{?}', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_inventory['gk'].most_common(125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Line-merger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a prototype for collecting the next lines recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*$MLY **$LMY\\t*SUBAI+/ [e2.46]'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Path('../source/patched/17.1Esdras.par').read_text().split('\\n')\n",
    "\n",
    "lines = test[3067]\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W/B/QWM/H\tKAI\\ {..dE)N TW=|} A)NASTH=NAI #\n",
      "\theb: W/B/QWM/H#\n",
      "\tgrk: KAI\\ {..dE)N TW=|} A)NASTH=NAI #{..dAU)TH\\N}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    \n",
    "    line = lines[i]\n",
    "    \n",
    "    if not line or ref_string.match(line):\n",
    "        i += 1\n",
    "        continue\n",
    "    \n",
    "    print(line)\n",
    "    heb_col, grk_col = line.split('\\t')\n",
    "    cont_lines = list(get_continued_columns(lines, i))\n",
    "    #print(cont_lines)\n",
    "    for hb_cc, gk_cc in cont_lines:\n",
    "        i += 1 # advance position in doc\n",
    "        heb_col += hb_cc\n",
    "        grk_col += gk_cc\n",
    "\n",
    "    print('\\theb:', heb_col)\n",
    "    print('\\tgrk:', grk_col)\n",
    "    print()\n",
    "            \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAI\\ {..dE)N TW=|} A)NASTH=NAI # match\n"
     ]
    }
   ],
   "source": [
    "cont_column = re.compile(r'[^\\s]+.*#\\s*$')\n",
    "\n",
    "for line in lines:\n",
    "    for col in line.split('\\t'):\n",
    "        if cont_column.match(col):\n",
    "            print(col, 'match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_is_continued(*'BR)Y W/B/$(RYM =:BR)WM$(RYM #\\tBAROUMSEWRIM {t}'.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
