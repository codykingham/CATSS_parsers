{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Parallel Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clean dataset is a modernization of the CATSS Database, presented with minimal changes, in UTF8, exported as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from greekutils import beta2unicode # do: pip install greek-utils==0.2\n",
    "from pprint import pprint\n",
    "\n",
    "data = Path('../source/patched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCAT transcription to UTF8\n",
    "# Greek to be handled by greekutils\n",
    "\n",
    "# Hebrew\n",
    "trans2utf8 = {\n",
    "    ')': 'א',\n",
    "    'B': 'ב',\n",
    "    'G': 'ג',\n",
    "    'D': 'ד',\n",
    "    'H': 'ה',\n",
    "    'W': 'ו',\n",
    "    'Z': 'ז',\n",
    "    'X': 'ח',\n",
    "    '+': 'ט',\n",
    "    'Y': 'י',\n",
    "    'K': 'כ',\n",
    "    'L': 'ל',\n",
    "    'M': 'מ',\n",
    "    'N': 'נ',\n",
    "    'S': 'ס',\n",
    "    '(': 'ע',\n",
    "    'P': 'פ',\n",
    "    'C': 'צ',\n",
    "    'Q': 'ק',\n",
    "    'R': 'ר',\n",
    "    '&': 'שׂ',\n",
    "    '$': 'שׁ',\n",
    "    'T': 'ת',\n",
    "    '-': '־',\n",
    "    '\\\\': '',\n",
    "    ' ': ' ',\n",
    "}\n",
    "\n",
    "def utf8_hebrew(string):\n",
    "    \"\"\"Convert transcribed Hebrew to UTF8\n",
    "    \n",
    "    NB: does not provide final letters (e.g. ם).\n",
    "    \"\"\"\n",
    "    utf8_string = ''\n",
    "    for c in string:\n",
    "        utf8_string += trans2utf8.get(c, '')\n",
    "    return utf8_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'συναγωγὴν'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta2unicode.convert('SUNAGWGH\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'היתה שׁמ בבית־לחממ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utf8_hebrew('HYTH $M B\\BYT-LXMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the files\n",
    "\n",
    "We process the CATSS database files into JSONs. \n",
    "\n",
    "The datastructure is illustrated below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[ # list of verses\n",
    "    \n",
    "    [ # list data for a verse\n",
    "    \n",
    "        'Gen 1:9',     # verse reference\n",
    "        \n",
    "        [ # three-list of text columns\n",
    "            \n",
    "            [ # Hebrew column A\n",
    "                ('מקום', ''), # text entry + text critical notes\n",
    "            ],\n",
    "            \n",
    "            [ # Hebrew column B\n",
    "                ('מקוה', '?'), # text entry + text critical notes\n",
    "            ], \n",
    "            \n",
    "            [ # Greek column\n",
    "                ('συναγωγὴν', ''), # text entry + text critical notes\n",
    "            ],   \n",
    "        ],\n",
    "    ],\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each list consists of a single verse, headed by a reference string. The \n",
    "second element in the list is a three-list of two-tuples.\n",
    "\n",
    "Each two-tuple represents a column in the database, and they consist \n",
    "of `(text, text-critical notes)`. Hebrew column B contains retroverted\n",
    "readings and it is frequently empty.\n",
    "\n",
    "Each column can contain multiple text entries, for cases where there are \n",
    "separate notes per column. For instance, the database might contain \n",
    "words wrapped in curly brackets `{}` with notations that are separate\n",
    "from another word that is not contained in them. Thus, each column\n",
    "can contain more than 1 entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_data = []\n",
    "\n",
    "# -- regex patterns --\n",
    "ref_string = re.compile(r'^[A-Za-z1-9/]+ \\d+:?\\d*$') # e.g. 'Gen 1:3'\n",
    "continued_column = re.compile(r'[^\\s]+.*#\\s*$') # '#' at end of col preceded by some non-space char\n",
    "content = re.compile(r'.*[^\\s].*') # string has some non-space char (content)\n",
    "\n",
    "test = []\n",
    "errors = []\n",
    "passages = set()\n",
    "\n",
    "def line_is_continued(col1, col2):\n",
    "    \"\"\"Return boolean whether any column in a line is continued in next line\"\"\"\n",
    "    if continued_column.match(col1) or continued_column.match(col2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_dataline(line):\n",
    "    \"\"\"Return boolean on whether a line contains data content\"\"\"\n",
    "    return all([\n",
    "        content.match(line), \n",
    "        not ref_string.match(line)\n",
    "    ])\n",
    "\n",
    "def get_continued_columns(lines, counter):\n",
    "    \"\"\"Recursively retrieve data-lines continued on next line (marked with #).\n",
    "    \n",
    "    The function recursively retrieves subsequent lines if a starting line\n",
    "    is marked with a continuation marker (#). Each line that is retrieved\n",
    "    must be split into its columns, and those columns in turn must be \n",
    "    checked for continuation markers. This is done recursively until there\n",
    "    is no continuation marker found. The function retrieves the lines using \n",
    "    the current index position; it advances the index by adding 1 each time. \n",
    "    It yields all additional columns it finds as 2-tuples.\n",
    "    \"\"\"\n",
    "    line = lines[counter]\n",
    "    if is_dataline(line):\n",
    "        heb_col, grk_col = line.split('\\t')\n",
    "        if line_is_continued(heb_col, grk_col):\n",
    "            counter += 1\n",
    "            next_cols = lines[counter].split('\\t')\n",
    "            yield next_cols\n",
    "            yield from get_continued_columns(lines, counter) # recursive call here\n",
    "\n",
    "# process files\n",
    "for file in sorted(data.glob('*.par')):\n",
    "    \n",
    "    # read the file\n",
    "    lines = file.read_text().split('\\n')\n",
    "    \n",
    "    verse_data = []\n",
    "    position = 0\n",
    "    \n",
    "    while position < len(lines):\n",
    "    \n",
    "        line = lines[position]\n",
    "    \n",
    "        # detect a new verse at verse reference string\n",
    "        if ref_string.match(line):\n",
    "            \n",
    "            # store last verse, make space for new one, store new one\n",
    "            if verse_data:\n",
    "                para_data.append(verse_data)\n",
    "                verse_data = []\n",
    "            verse_data.append(line)\n",
    "        \n",
    "        elif line:\n",
    "            \n",
    "            # extract the two columns\n",
    "            try:\n",
    "                heb_col, grk_col = line.split('\\t')\n",
    "            except:\n",
    "                raise Exception(file.name, position, line)\n",
    "            \n",
    "            try:\n",
    "                # collect parts of the columns continued on next line(s) in doc\n",
    "                # this is done recursively to ensure all lines are retrieved\n",
    "                cont_cols = list(get_continued_columns(lines, position))\n",
    "\n",
    "                for hb_cc, gk_cc in cont_cols:\n",
    "                    position += 1\n",
    "                    heb_col += hb_cc\n",
    "                    grk_col += gk_cc\n",
    "                    \n",
    "            except:\n",
    "                errors.append((file.name, position, line))\n",
    "                \n",
    "            if len(cont_cols) > 1:\n",
    "                test.append((file.name, position, line, heb_col, grk_col))\n",
    "                \n",
    "        # it's an empty line; move on\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        position += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('08.JudgesB.par',\n",
      " 452,\n",
      " 'W/)T BNT/YH {..rL)}\\tOU)DE\\\\ TA\\\\ PERI/OIKA AU)TH=S {d} #',\n",
      " 'W/)T BNT/YH {..rL)}###',\n",
      " 'OU)DE\\\\ TA\\\\ PERI/OIKA AU)TH=S {d} #OU)DE\\\\ TA\\\\S QUGATE/RAS AU)TH=S {d} '\n",
      " '#{...OU)DE\\\\ TA\\\\ PERI/OIKA AU)TH=S} {d} #{...OU)DE\\\\ TA\\\\S QUGATE/RAS '\n",
      " 'AU)TH=S}')\n",
      "\n",
      "('11.1Sam.par',\n",
      " 6643,\n",
      " 'W/HXRMTM\\tKAI\\\\ IERIM {t} {d} {...KAI\\\\ #',\n",
      " 'W/HXRMTM##',\n",
      " 'KAI\\\\ IERIM {t} {d} {...KAI\\\\ #E)COLEQREU/SEIS AU)TO\\\\N {d} KAI\\\\ '\n",
      " '#A)NAQEMATIEI=S AU)TO\\\\N}')\n",
      "\n",
      "('13.1Kings.par',\n",
      " 2979,\n",
      " 'H/MMLKWT ={d}H/MLKYM <5.4>\\tTAI=S BASILEI/AIS [2.46b] {d} #',\n",
      " 'H/MMLKWT ={d}H/MLKYM <5.4>##',\n",
      " 'TAI=S BASILEI/AIS [2.46b] {d} #TOI=S BASILEU=SIN [2.46k] #TW=N BASILE/WN '\n",
      " '[10.26a]')\n",
      "\n",
      "('17.1Esdras.par',\n",
      " 532,\n",
      " 'H/QYNWT =SPR DBRY ?H/YMYM\\tTH=| BI/BLIW| TW=N I(STOROUME/NWN #',\n",
      " 'H/QYNWT =SPR DBRY ?H/YMYM# ?L/MLKY :YHWDH#',\n",
      " 'TH=| BI/BLIW| TW=N I(STOROUME/NWN #PERI\\\\ TW=N BASILE/WN TH=S I)OUDAI/AS '\n",
      " '#[cc35.25]')\n",
      "\n",
      "('23.Prov.par',\n",
      " 9159,\n",
      " 'XRDT ={d}XRPT .dp\\tFOBHQE/NTES {d} KAI\\\\ AI)SXUNQE/NTES #',\n",
      " 'XRDT ={d}XRPT .dp{...} #)DM',\n",
      " 'FOBHQE/NTES {d} KAI\\\\ AI)SXUNQE/NTES #{d} {...A)SE/BEIA}A)NQRW/POUS {d} '\n",
      " '{...A)NDRI\\\\}')\n",
      "\n",
      "('40.Isaiah.par',\n",
      " 2381,\n",
      " '$+P W/(BR (D CW)R YGY(\\tA)/NQRWPON O(\\\\S DUNH/SETAI KEFALH\\\\N #',\n",
      " '$+P W/(BR (D CW)R YGY(##',\n",
      " 'A)/NQRWPON O(\\\\S DUNH/SETAI KEFALH\\\\N #A)=RAI {d?} {..?H)\\\\ DUNATO\\\\N '\n",
      " '#SUNTELE/SASQAI/ TI}')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for case in test:\n",
    "    pprint(case)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Line-merger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a prototype for collecting the next lines recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t#',\n",
       " '--+\\tE)N AU)TAI=S',\n",
       " 'W/)T BGDY\\tKAI\\\\ TOU\\\\S XITW=NAS',\n",
       " 'BN/YW\\tTOI=S UI(OI=S AARWN']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Path('../source/patched/02.Exodus.par').read_text().split('\\n')\n",
    "\n",
    "lines = test[16283:16287]\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W/B/QWM/H\tKAI\\ {..dE)N TW=|} A)NASTH=NAI #\n",
      "\theb: W/B/QWM/H#\n",
      "\tgrk: KAI\\ {..dE)N TW=|} A)NASTH=NAI #{..dAU)TH\\N}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    \n",
    "    line = lines[i]\n",
    "    \n",
    "    if not line or ref_string.match(line):\n",
    "        i += 1\n",
    "        continue\n",
    "    \n",
    "    print(line)\n",
    "    heb_col, grk_col = line.split('\\t')\n",
    "    cont_lines = list(get_continued_columns(lines, i))\n",
    "    #print(cont_lines)\n",
    "    for hb_cc, gk_cc in cont_lines:\n",
    "        i += 1 # advance position in doc\n",
    "        heb_col += hb_cc\n",
    "        grk_col += gk_cc\n",
    "\n",
    "    print('\\theb:', heb_col)\n",
    "    print('\\tgrk:', grk_col)\n",
    "    print()\n",
    "            \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAI\\ {..dE)N TW=|} A)NASTH=NAI # match\n"
     ]
    }
   ],
   "source": [
    "cont_column = re.compile(r'[^\\s]+.*#\\s*$')\n",
    "\n",
    "for line in lines:\n",
    "    for col in line.split('\\t'):\n",
    "        if cont_column.match(col):\n",
    "            print(col, 'match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_is_continued(*'BR)Y W/B/$(RYM =:BR)WM$(RYM #\\tBAROUMSEWRIM {t}'.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
